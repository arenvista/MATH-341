---
id: L01
aliases: []
tags: []
---
[Course Website](https://userpages.umbc.edu/~sousedik/classes/341s26/)

# Course Overview

## Topics
1. Core Linear Algebra Ideas for Data Problems
2. Matrix Factorization 
    - $A=LU$ 
        - L (Lower left triangular matrix)
        - U (Upper right triangular matrix?)
    - $A = QR$
        - Q (Orthonormal Matrixies)
        - R (upper right triangular matrix) 
        - QR is good for least squares problems 
3. SVD and Eigenvalues
4. Comnnect Matricies to Probability and Statistics 
5. Optimization Methods (Conjugate Gradients [and variants])
6. Explain the mathematical core of deep learning

## Graded Content
Midterm March 12th 
Final: Largely based on HW problems 
HW: (uncertain; on BB)
Project: (potentially) TBD: Prior to spring break

# Basic Matrix Algebra

## Vectors
> [!def] Vector Definition
> A **vector** is a element that has both a *direction* and *magnitude*
> Vectors can be denoted as:
> $$
> v =  
> \begin{bmatrix}
> a \\ b \\ c 
> \end{bmatrix}
> $$

> [!def] Vector Space Properties 
> $A$ is a vector space if the following properties are maintained: 
> 1. **Vector Addition:** $u,v \in A \implies u+v \in A$
> 1. **Scalar Multiplication:** $u \in A, c \in \mathbb{R} \implies uc \in A$
> 1. **Zero Vector (Origin/Identity):** $\exists ~\vec{0} \in A$

### Vector Operations

> [!def] Dot Product
> Consider $\vec{u} \cdot \vec{v}$ we can write this in the following ways:  
> $$
> \vec{u} \cdot \vec{v} = \vec{u}^T \vec{v} 
> = [u_1,u_2,u_3] \begin{bmatrix}
> v_1 \\
> v_2 \\
> v_3
> \end{bmatrix}
> = c
> $$
> > [!note] Observe Change in Set
 > Note: Where $c \in \mathbb{R}$, recall that when computing a dot product the final output is a **scalar value** 

> [!def] Vector Normal
> The norm of a vector, denoted as $||\vec{u}||$. This is the same as the length of the vector:
> $$
> ||\vec{u}|| = \sqrt{\vec{u} \cdot \vec{u}} = \sqrt{\vec{u}^T \vec{u}}
> $$

> [!def] Angle Between Vectors
> Consider we have vectors, $\vec{w}, \vec{v}$. 
> Consider the relationship:
> $$
> \vec{v} \cdot \vec{w} = ||\vec{v}|| ~||\vec{w}|| ~cos(\theta)
> $$
> We can compwte the angle between them as follows:
> $$
> cos(\theta) = \frac{\vec{w}\vec{v}}{||\vec{w}|| ~||\vec{v}||}
> $$
> 
> > [!cor] Orthogonality
> > If the $cos(\theta)$ between two vectors is zero. Then we can say that they are orthogonal towards each other.

> [!def] Orthonormal Vectors
> Simply, orthogonal vectors, normalized to magnitude of one unit.
> $$
> \begin{align}
> & ||v \cdot w||^2 \\
> & = (v+w) \cdot (v+w) \\
> &= v \cdot v + v \cdot w + w \cdot v + w \cdot w \\
> & = ||v||^2 + ||w||^2 + 2(v \cdot w)
> \end{align}
> $$


> [!def] Triangle Inequality
> Observe (true by trig):
> $$
> ||v+w|| \leq  ||v|| + ||w||
> $$


> [!def] Matrix Multiplication
> $$
> Ax = 
> \begin{bmatrix}
> 2 & 5 \\
> 3 & 7
> \end{bmatrix}
> \begin{bmatrix}
> 1 \\ 1
> \end{bmatrix} =
> \begin{bmatrix}
> 2*1 + 5*1 \\
> 3*1 + 7*1
> \end{bmatrix} = 
> \begin{bmatrix}
> 7 \\ 10
> \end{bmatrix}
> $$
> Observe the output is the result of a linear combination of columns of A
> $$
> \begin{bmatrix}
> \vec{a_1} & \vec{a_2}
> \end{bmatrix}
> \begin{bmatrix}
> x_1 \\ x_2
> \end{bmatrix} = 
> x_1a_1 + x_2a_2
> $$
> Spesicially $x_1a_1 + x_2a_2$ is the linear combination of columns of A

> [!def] Column Space of A
> $Col(A) =$ Column Space of A = All Possible Linear Combinations of Cols of A

> [!thm] Independence of Columns
> $$
> A_2 = 
> \begin{bmatrix}
> a & b & c \\
> d & e & f
> \end{bmatrix}
> $$
> Observe this matrix:
> - Composes of vectors that exist in 2D (num or rows)
> - Needs a 3D space (3x2) to be multiplied
>
> Observe must be linearly dependent; At most 2 vectors in 2D. 
> We say the columns of $A$ are independent if no column is a linear combination of other columns
>
> In other words: $Ax = 0$ only when $x=0$

> [!def] Rank
> Rank = number of independent columns = number of independent rows
> This follows that the columns are independent iff the rows are independent

*Next class will discuss matrix matrix multiplication; then LU factorization* 
